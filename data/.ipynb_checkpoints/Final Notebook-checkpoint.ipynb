{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geog 80 Final - Ryan Meyer\n",
    "## COVID-19 Pandemic in the United States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Data loading and processing\n",
    "First, we shall load in the covid case data, US Census 2019 population estimates, as well as some GeoJSON data containing county geometry. Some cleaning needs to be done to match the format of FIPS codes between datasets. Additionally, we will clean the population dataset and join it via census area names. Finally, we divide the joined table by the data from the US population table to yield the final dataset: a dataframe of covid cases per capita for each county for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>11/24/20</th>\n",
       "      <th>11/25/20</th>\n",
       "      <th>11/26/20</th>\n",
       "      <th>11/27/20</th>\n",
       "      <th>11/28/20</th>\n",
       "      <th>11/29/20</th>\n",
       "      <th>11/30/20</th>\n",
       "      <th>12/1/20</th>\n",
       "      <th>12/2/20</th>\n",
       "      <th>POPESTIMATE2019</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abbeville,South Carolina</th>\n",
       "      <td>84045001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>45001</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>US</td>\n",
       "      <td>34.223334</td>\n",
       "      <td>-82.461707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.038080</td>\n",
       "      <td>0.038080</td>\n",
       "      <td>0.038651</td>\n",
       "      <td>0.039141</td>\n",
       "      <td>0.039181</td>\n",
       "      <td>0.039426</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>0.039874</td>\n",
       "      <td>24527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acadia,Louisiana</th>\n",
       "      <td>84022001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>22001</td>\n",
       "      <td>Acadia</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>US</td>\n",
       "      <td>30.295065</td>\n",
       "      <td>-92.414197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062358</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.063663</td>\n",
       "      <td>0.063663</td>\n",
       "      <td>0.064179</td>\n",
       "      <td>0.064115</td>\n",
       "      <td>0.064937</td>\n",
       "      <td>0.065743</td>\n",
       "      <td>62045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accomack,Virginia</th>\n",
       "      <td>84051001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>51001</td>\n",
       "      <td>Accomack</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>US</td>\n",
       "      <td>37.767072</td>\n",
       "      <td>-75.632346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040537</td>\n",
       "      <td>0.040692</td>\n",
       "      <td>0.040970</td>\n",
       "      <td>0.041156</td>\n",
       "      <td>0.041466</td>\n",
       "      <td>0.041620</td>\n",
       "      <td>0.041651</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.042053</td>\n",
       "      <td>32316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada,Idaho</th>\n",
       "      <td>84016001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>16001</td>\n",
       "      <td>Ada</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>US</td>\n",
       "      <td>43.452658</td>\n",
       "      <td>-116.241552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049887</td>\n",
       "      <td>0.050520</td>\n",
       "      <td>0.050520</td>\n",
       "      <td>0.051540</td>\n",
       "      <td>0.052184</td>\n",
       "      <td>0.052668</td>\n",
       "      <td>0.053367</td>\n",
       "      <td>0.054281</td>\n",
       "      <td>0.055076</td>\n",
       "      <td>481587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adair,Iowa</th>\n",
       "      <td>84019001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>19001</td>\n",
       "      <td>Adair</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>US</td>\n",
       "      <td>41.330756</td>\n",
       "      <td>-94.471059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058865</td>\n",
       "      <td>0.059424</td>\n",
       "      <td>0.059983</td>\n",
       "      <td>0.059983</td>\n",
       "      <td>0.061521</td>\n",
       "      <td>0.061661</td>\n",
       "      <td>0.061661</td>\n",
       "      <td>0.062081</td>\n",
       "      <td>0.062640</td>\n",
       "      <td>7152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               UID iso2 iso3  code3   FIPS     Admin2  \\\n",
       "place                                                                   \n",
       "Abbeville,South Carolina  84045001   US  USA    840  45001  Abbeville   \n",
       "Acadia,Louisiana          84022001   US  USA    840  22001     Acadia   \n",
       "Accomack,Virginia         84051001   US  USA    840  51001   Accomack   \n",
       "Ada,Idaho                 84016001   US  USA    840  16001        Ada   \n",
       "Adair,Iowa                84019001   US  USA    840  19001      Adair   \n",
       "\n",
       "                          Province_State Country_Region        Lat  \\\n",
       "place                                                                \n",
       "Abbeville,South Carolina  South Carolina             US  34.223334   \n",
       "Acadia,Louisiana               Louisiana             US  30.295065   \n",
       "Accomack,Virginia               Virginia             US  37.767072   \n",
       "Ada,Idaho                          Idaho             US  43.452658   \n",
       "Adair,Iowa                          Iowa             US  41.330756   \n",
       "\n",
       "                               Long_       ...         11/24/20  11/25/20  \\\n",
       "place                                      ...                              \n",
       "Abbeville,South Carolina  -82.461707       ...         0.037632  0.038080   \n",
       "Acadia,Louisiana          -92.414197       ...         0.062358  0.062600   \n",
       "Accomack,Virginia         -75.632346       ...         0.040537  0.040692   \n",
       "Ada,Idaho                -116.241552       ...         0.049887  0.050520   \n",
       "Adair,Iowa                -94.471059       ...         0.058865  0.059424   \n",
       "\n",
       "                          11/26/20  11/27/20  11/28/20  11/29/20  11/30/20  \\\n",
       "place                                                                        \n",
       "Abbeville,South Carolina  0.038080  0.038651  0.039141  0.039181  0.039426   \n",
       "Acadia,Louisiana          0.062600  0.063663  0.063663  0.064179  0.064115   \n",
       "Accomack,Virginia         0.040970  0.041156  0.041466  0.041620  0.041651   \n",
       "Ada,Idaho                 0.050520  0.051540  0.052184  0.052668  0.053367   \n",
       "Adair,Iowa                0.059983  0.059983  0.061521  0.061661  0.061661   \n",
       "\n",
       "                           12/1/20   12/2/20  POPESTIMATE2019  \n",
       "place                                                          \n",
       "Abbeville,South Carolina  0.039630  0.039874            24527  \n",
       "Acadia,Louisiana          0.064937  0.065743            62045  \n",
       "Accomack,Virginia         0.041992  0.042053            32316  \n",
       "Ada,Idaho                 0.054281  0.055076           481587  \n",
       "Adair,Iowa                0.062081  0.062640             7152  \n",
       "\n",
       "[5 rows x 328 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import warnings\n",
    "\n",
    "caseDataFile = \"https://raw.githubusercontent.com/ryanpmeyer/Geog80Final/master/data/time_series_covid19_confirmed_US.csv\"\n",
    "populationDataFile = \"https://raw.githubusercontent.com/ryanpmeyer/Geog80Final/master/data/co-est2019-alldata.csv\"\n",
    "geoJSONFile = 'https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json'\n",
    "\n",
    "def getData():\n",
    "  with urlopen(geoJSONFile) as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "\n",
    "  # get covid case data, clean FIPS code\n",
    "  covid_cases_raw = pd.read_csv(caseDataFile)\n",
    "  covid_cases = covid_cases_raw.dropna().reindex()\n",
    "  old_fips = covid_cases['FIPS'].astype('int32').astype(str)\n",
    "  max_fips_code_len = max([len(x) for x in old_fips])\n",
    "  new_fips = list(old_fips)\n",
    "  for i in range(len(old_fips)):\n",
    "      while len(new_fips[i]) < max_fips_code_len:\n",
    "          new_fips[i] = '0' + new_fips[i]\n",
    "  covid_cases['FIPS'] = new_fips\n",
    "\n",
    "  # get US population data, clean county names\n",
    "  us_pop_raw = pd.read_csv(populationDataFile, encoding='latin1')\n",
    "  us_pop = us_pop_raw[us_pop_raw['CTYNAME'] != us_pop_raw['STNAME']]\n",
    "  strings2remove = [' County',' Borough',' Census Area',' Municipality',' Parish', ' city', ' City']\n",
    "  for string in strings2remove:\n",
    "      us_pop['CTYNAME'] = us_pop['CTYNAME'].str.replace(string,\"\",case=False)\n",
    "  us_pop['CTYNAME'] = us_pop['CTYNAME'].str.strip()\n",
    "\n",
    "  # remove data from population with duplicate locations\n",
    "  indicies_to_remove = []\n",
    "  for state in set(us_pop['STNAME']):\n",
    "    counties_in_state = us_pop[us_pop['STNAME']==state]\n",
    "    for cty in set(counties_in_state['CTYNAME']):\n",
    "      rows = counties_in_state[counties_in_state['CTYNAME']==cty]\n",
    "      if len(rows) > 1:\n",
    "        rows_index = rows.index\n",
    "        highest_pop_i = rows['POPESTIMATE2019'].argmax()\n",
    "        for i in rows_index:\n",
    "          if i != highest_pop_i:\n",
    "            indicies_to_remove.append(i)\n",
    "  us_pop.drop(index=indicies_to_remove,inplace=True)\n",
    "  us_pop.reindex(copy=False)\n",
    "\n",
    "  # join tables and divide case nums by population\n",
    "  us_pop['place'] = us_pop['CTYNAME'] + ',' + us_pop['STNAME']\n",
    "  covid_cases['place'] = covid_cases['Admin2'] + ',' + covid_cases['Province_State']\n",
    "  joined = covid_cases.set_index('place').join(us_pop.set_index(\"place\")['POPESTIMATE2019'],\n",
    "              how='inner', lsuffix='County', rsuffix='').sort_index()\n",
    "  for col in joined.columns[11:len(joined.columns)-1]:\n",
    "      joined[col] = joined[col] / joined['POPESTIMATE2019']\n",
    "\n",
    "\n",
    "\n",
    "  used_fips = set(joined['FIPS'])\n",
    "  # remove data from GeoJSON without matching FIPS code in case data\n",
    "  \n",
    "  cleaned_features = list(counties['features'])\n",
    "  for feature in counties['features']:\n",
    "    if feature['id'] not in used_fips:\n",
    "      cleaned_features.remove(feature)\n",
    "  counties['features'] = cleaned_features\n",
    "\n",
    "  return counties, joined\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    counties, caseData = getData()\n",
    "caseData.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Choropleth analysis\n",
    "\n",
    "Now we have data for each US county's confirmed cases per capita for each day from 1/22 - 12/2. Next we will look at a choropleth map of this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipyleaflet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a1b7ab132a98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minteract\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minteract_manual\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mipyleaflet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbranca\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ipyleaflet'"
     ]
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipyleaflet\n",
    "import ipywidgets as widgets\n",
    "import datetime\n",
    "import branca\n",
    "\n",
    "NUMDAYS = 315\n",
    "STARTDATE = datetime.datetime(2020,1,22)\n",
    "max_caseload = max(caseData['12/2/20'])\n",
    "\n",
    "\n",
    "def get_colorscale():\n",
    "  return branca.colormap.linear.YlOrRd_09.scale(0, max_caseload)\n",
    "\n",
    "def get_date_string(date):\n",
    "  date_obj = STARTDATE + datetime.timedelta(days=date) # get date object of date # of days after STARTDATE\n",
    "  date_string = date_obj.strftime(\"%x\") # format date into D/M/Y\n",
    "  if date_string[0] == '0': # no leading zeros in month\n",
    "    date_string = date_string[1:]\n",
    "  if date_string[date_string.find('/')+1] == '0': # no leading zeros in day\n",
    "    date_string = date_string[0:date_string.find('/')+1] + date_string[date_string.find('/')+2:]\n",
    "  return date_string\n",
    "\n",
    "def get_styler(data_series):\n",
    "    colorscale = get_colorscale()\n",
    "    def style(feature):\n",
    "      value = data_series.get(feature['id'])\n",
    "      if value is None:\n",
    "        value = -1\n",
    "      return {\n",
    "          'color': 'black',\n",
    "          'fillColor': colorscale(value) if value != -1 else 'black'\n",
    "      }\n",
    "    return style\n",
    "\n",
    "def get_choropleth(date):\n",
    "\n",
    "  date_string = get_date_string(date)\n",
    "  data_series = caseData.set_index('FIPS')[date_string]\n",
    "\n",
    "  m = ipyleaflet.Map(center=[48,-102],zoom=4)\n",
    "\n",
    "  choropleth_layer = ipyleaflet.GeoJSON(\n",
    "      data=counties,\n",
    "      style={\n",
    "          'opcaity':1,\n",
    "          'fillOpacity':.7,\n",
    "          'weight':1\n",
    "      },\n",
    "      style_callback=get_styler(data_series)\n",
    "  )\n",
    "  m.add_layer(choropleth_layer)\n",
    "\n",
    "  return m, choropleth_layer\n",
    "\n",
    "def get_map_updater(layer):\n",
    "  def update(date):\n",
    "    date_string = get_date_string(date)\n",
    "    layer.style_callback = get_styler(caseData.set_index('FIPS')[date_string])\n",
    "  return update\n",
    "\n",
    "def get_map():\n",
    "  m = get_choropleth(0)\n",
    "  return m\n",
    "\n",
    "m, layer = get_map()\n",
    "update = get_map_updater(layer)\n",
    "interact(update, date=widgets.IntSlider(min=0, max=NUMDAYS, step=1, value=0))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
